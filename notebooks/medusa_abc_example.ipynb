{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee706e3",
   "metadata": {},
   "source": [
    "# `MEDUSA`\n",
    "aka. Dynamic-Prospective LCA aka. Union(premise, temporalis)\n",
    "\n",
    "example with abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8cd7a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bw_temporalis import easy_timedelta_distribution, TemporalDistribution\n",
    "from edge_extractor import EdgeExtracter\n",
    "from medusa_tools import *\n",
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51fc994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.projects.delete_project(\"medusa_abc_example\")\n",
    "bd.projects.purge_deleted_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52469cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 33554.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n",
      "Not able to determine geocollections for all datasets. This database is not ready for regionalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24385.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n",
      "Not able to determine geocollections for all datasets. This database is not ready for regionalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34379.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n",
      "Not able to determine geocollections for all datasets. This database is not ready for regionalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 46603.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bd.projects.set_current(\"medusa_abc_example\")\n",
    "\n",
    "bd.Database('medusa-bio').write({\n",
    "            ('medusa-bio', \"CO2\"): {\n",
    "                \"type\": \"biosphere\",\n",
    "                \"name\": \"carbon dioxide\",\n",
    "                \"temporalis code\": \"co2\",\n",
    "            },\n",
    "        },\n",
    ")\n",
    "\n",
    "bd.Database(\"background_2024\").write(\n",
    "    {\n",
    "        (\"background_2024\", \"C\"): {\n",
    "            'name': 'C',\n",
    "            'location': 'somewhere',\n",
    "            'reference product': 'C',\n",
    "            \"exchanges\": [\n",
    "                {\n",
    "                    'amount': 1,\n",
    "                    'type': 'production',\n",
    "                    'input': (\"background_2024\", 'C'),\n",
    "                },\n",
    "                \n",
    "                {\n",
    "                    \"amount\": 5,\n",
    "                    \"input\": (\"medusa-bio\", \"CO2\"),\n",
    "                    \"type\": \"biosphere\",\n",
    "                },\n",
    "            ],       \n",
    "        },\n",
    "    },\n",
    "    \n",
    ")\n",
    "\n",
    "bd.Database(\"background_2022\").write(\n",
    "    {\n",
    "        (\"background_2022\", \"C\"): {\n",
    "            'name': 'C',\n",
    "            'location': 'somewhere',\n",
    "            'reference product': 'C',\n",
    "            \"exchanges\": [\n",
    "                {\n",
    "                    'amount': 1,\n",
    "                    'type': 'production',\n",
    "                    'input': (\"background_2022\", 'C'),\n",
    "                },                   \n",
    "                {\n",
    "                    \"amount\": 15,\n",
    "                    \"input\": (\"medusa-bio\", \"CO2\"),\n",
    "                    \"type\": \"biosphere\",\n",
    "                },\n",
    "            ],   \n",
    "        },\n",
    "    },\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "bd.Database(\"foreground\").write(\n",
    "    {\n",
    "        (\"foreground\", \"A\"): {\n",
    "            'name': 'A',\n",
    "            'location': 'somewhere',\n",
    "            'reference product': 'A',\n",
    "            \"exchanges\": [\n",
    "                {\n",
    "                    'amount': 1,\n",
    "                    'type': 'production',\n",
    "                    'input': ('foreground', 'A'),\n",
    "                },                 \n",
    "                {\n",
    "                    \"amount\": 1,\n",
    "                    \"input\": (\"foreground\", \"B\"),\n",
    "                    'temporal_distribution':                     easy_timedelta_distribution(\n",
    "                    start=-2,\n",
    "                    end=0, # Range includes both start and end\n",
    "                    resolution=\"Y\",  # M for months, Y for years, etc.\n",
    "                    steps=2,\n",
    "                ),\n",
    "                    \"type\": \"technosphere\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \n",
    "        (\"foreground\", \"B\"): {\n",
    "            'name': 'B',\n",
    "            'location': 'somewhere',\n",
    "            'reference product': 'B',\n",
    "            \"exchanges\": [\n",
    "                {\n",
    "                    'amount': 1,\n",
    "                    'type': 'production',\n",
    "                    'input': ('foreground', 'B'),\n",
    "                },\n",
    "                {\n",
    "                    \"amount\": 1,\n",
    "                    \"input\": (\"background_2024\", \"C\"),\n",
    "                    \"type\": \"technosphere\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "bd.Method((\"GWP\", \"example\")).write([\n",
    "((\"medusa-bio\", \"CO2\"), 1),\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9405d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = {('foreground', 'A'): 1}\n",
    "gwp = ('GWP', 'example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ced634",
   "metadata": {},
   "source": [
    "# Static LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca6b8f2-12a3-43f9-8be2-c6a898268adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static LCA score: 5.0\n"
     ]
    }
   ],
   "source": [
    "slca = bc.LCA(demand, gwp)\n",
    "slca.lci()\n",
    "slca.lcia()\n",
    "print(f'Static LCA score: {slca.score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461bbb5",
   "metadata": {},
   "source": [
    "# `MEDUSA` LCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f0158",
   "metadata": {},
   "source": [
    "A MEDUSA LCA builds upon a static LCA, but adds a temporal dimensions, linking to prospective LCA databases. Similarly to a `Temporalis LCA`, the supply chain graph is traversed, taking into account temporal distributions of the edges. \n",
    "\n",
    "For now, only the foreground system is assumed to have temporal distributions. Therefore, we define a filter function, that tells to EdgeExtracter (which is doing the actual graph traversal and saves the edges with respective timestamps), when a database that is known to have no temporal distributions (i.e., the prospective background databases) is reached, so that the traversal can be stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31af46a8-ceee-4ccd-8964-fbc9698f43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIPPABLE = [node.id for node in bd.Database('background_2020')] + [\n",
    "    node.id for node in bd.Database('background_2023')\n",
    "]\n",
    "\n",
    "def filter_function(database_id: int) -> bool:\n",
    "    return database_id in SKIPPABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead855e",
   "metadata": {},
   "source": [
    "Now we can do the graph traversal and create a timeline of edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d56515-377a-4086-921f-c8fd7efca39f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting graph traversal\n",
      "Calculation count: 2\n"
     ]
    }
   ],
   "source": [
    "eelca = EdgeExtracter(slca, edge_filter_function=filter_function)\n",
    "timeline = eelca.build_edge_timeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2733bf",
   "metadata": {},
   "source": [
    "Next, we define a dictionary containing the dates of our prospective background databases. Using this, we can create a timeline dataframe. \n",
    "\n",
    "The dates of the edges are mapped to the prospective background databases; interpolation is used for dates in between the dates of the background databases. The default is linear interpolation, another currently included option is \"nearest\", choosing the next best fitting database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b5649e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>producer</th>\n",
       "      <th>consumer</th>\n",
       "      <th>amount</th>\n",
       "      <th>date</th>\n",
       "      <th>interpolation_weights</th>\n",
       "      <th>producer_name</th>\n",
       "      <th>consumer_name</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>{'background_2022': 0.4996577686516085, 'backg...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>{'background_2022': 0.4996577686516085, 'backg...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>{'background_2022': 0.2498288843258042, 'backg...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>{'background_2022': 0.2498288843258042, 'backg...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>{'background_2024': 1}</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>{'background_2024': 1}</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>{'background_2024': 1}</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  producer  consumer    amount       date  \\\n",
       "0  2022         2         5  0.333333 2022-01-01   \n",
       "1  2022         5         4  0.333333 2022-01-01   \n",
       "2  2023         2         5  0.333333 2023-01-01   \n",
       "3  2023         5         4  0.333333 2023-01-01   \n",
       "4  2024         2         5  0.333333 2024-01-01   \n",
       "5  2024         4        -1       1.0 2024-01-01   \n",
       "6  2024         5         4  0.333333 2024-01-01   \n",
       "\n",
       "                               interpolation_weights producer_name  \\\n",
       "0  {'background_2022': 0.4996577686516085, 'backg...             C   \n",
       "1  {'background_2022': 0.4996577686516085, 'backg...             B   \n",
       "2  {'background_2022': 0.2498288843258042, 'backg...             C   \n",
       "3  {'background_2022': 0.2498288843258042, 'backg...             B   \n",
       "4                             {'background_2024': 1}             C   \n",
       "5                             {'background_2024': 1}             A   \n",
       "6                             {'background_2024': 1}             B   \n",
       "\n",
       "  consumer_name  timestamp  \n",
       "0             B       2022  \n",
       "1             A       2022  \n",
       "2             B       2023  \n",
       "3             A       2023  \n",
       "4             B       2024  \n",
       "5            -1       2024  \n",
       "6             A       2024  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_date_dict = {\n",
    "            datetime.strptime(\"2020\", \"%Y\"): 'background_2022',\n",
    "            datetime.strptime(\"2024\", \"%Y\"): 'background_2024',\n",
    "        }\n",
    "\n",
    "timeline_df = create_grouped_edge_dataframe(timeline, database_date_dict, interpolation_type=\"linear\")\n",
    "timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2eb640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All databases in database_date_dict exist as brightway project databases\n"
     ]
    }
   ],
   "source": [
    "# check that the strings of the databases (values of database_date_dict) exist in the databases of the brightway2 project:\n",
    "for db in database_date_dict.values():\n",
    "    assert db in bd.databases, f\"{db} not in your brightway2 project databases. Please check spelling of this database in database_date_dict and whether you are in the correct project.\"\n",
    "else:\n",
    "    print(\"All databases in database_date_dict exist as brightway project databases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32fc50",
   "metadata": {},
   "source": [
    "Now, we want to create a datapackage that takes care of relinking processes to our prospective databases. To do so, we need to provide the timeline dataframe, the dict of prospective databases and corresponding years, and a new dictionary that defines at which point in time our functional unit is assessed *(We can probably include this information in the database_date_dict in the future, but for now, this works)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d48585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 2024}\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m demand_timing_dict \u001b[38;5;241m=\u001b[39m create_demand_timing_dict(timeline_df, demand)\n\u001b[0;32m----> 3\u001b[0m dp \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_datapackage_from_edge_timeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeline_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase_date_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemand_timing_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Coding/tictac_lca/medusa_tools.py:361\u001b[0m, in \u001b[0;36mcreate_datapackage_from_edge_timeline\u001b[0;34m(timeline, database_date_dict, demand_timing, datapackage, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m     consumer_timestamps[\n\u001b[1;32m    356\u001b[0m         row\u001b[38;5;241m.\u001b[39mproducer\n\u001b[1;32m    357\u001b[0m     ] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    358\u001b[0m         row\u001b[38;5;241m.\u001b[39mtimestamp\n\u001b[1;32m    359\u001b[0m     )  \u001b[38;5;66;03m# the year of the producer will be the consumer year for this procuess until a it becomesa producer again\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# print(row.timestamp, row.producer, row.consumer, consumer_timestamps[row.consumer])\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[43madd_row_to_datapackage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatapackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase_date_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdemand_timing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsumer_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Adding ones on diagonal for new nodes\u001b[39;00m\n\u001b[1;32m    371\u001b[0m datapackage\u001b[38;5;241m.\u001b[39madd_persistent_vector(\n\u001b[1;32m    372\u001b[0m     matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtechnosphere_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     name\u001b[38;5;241m=\u001b[39muuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex,\n\u001b[1;32m    374\u001b[0m     data_array\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(new_nodes)),\n\u001b[1;32m    375\u001b[0m     indices_array\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([(i, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m new_nodes], dtype\u001b[38;5;241m=\u001b[39mbwp\u001b[38;5;241m.\u001b[39mINDICES_DTYPE),\n\u001b[1;32m    376\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Coding/tictac_lca/medusa_tools.py:265\u001b[0m, in \u001b[0;36mcreate_datapackage_from_edge_timeline.<locals>.add_row_to_datapackage\u001b[0;34m(row, datapackage, database_date_dict, demand_timing, new_nodes, consumer_timestamps)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(consumer_timestamps)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(row\u001b[38;5;241m.\u001b[39mconsumer)\n\u001b[0;32m--> 265\u001b[0m new_consumer_id \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mconsumer \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000000\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mconsumer_timestamps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsumer\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# print(f'New consumer id = {new_consumer_id}')\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# print(f'New added year= {extract_date_as_integer(row.date)}')\u001b[39;00m\n\u001b[1;32m    268\u001b[0m new_producer_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    269\u001b[0m     row\u001b[38;5;241m.\u001b[39mproducer \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000000\u001b[39m \u001b[38;5;241m+\u001b[39m row\u001b[38;5;241m.\u001b[39mtimestamp\n\u001b[1;32m    270\u001b[0m )  \u001b[38;5;66;03m# In case the producer comes from a background database, we overwrite this. It currently still gets added to new_nodes, but this is not necessary.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "demand_timing_dict = create_demand_timing_dict(timeline_df, demand)\n",
    "\n",
    "dp = create_datapackage_from_edge_timeline(timeline_df, database_date_dict, demand_timing_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5ff18",
   "metadata": {},
   "source": [
    "Finally, we just have to reformat our input data for the LCA, add our datapackage containing the patches, and run the lca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bba776",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_medusa_lca_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fu, data_objs, remapping \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_medusa_lca_inputs\u001b[49m(demand\u001b[38;5;241m=\u001b[39mdemand, demand_timing_dict\u001b[38;5;241m=\u001b[39mdemand_timing_dict, method\u001b[38;5;241m=\u001b[39mgwp) \n\u001b[1;32m      2\u001b[0m lca \u001b[38;5;241m=\u001b[39m bc\u001b[38;5;241m.\u001b[39mLCA(fu, data_objs \u001b[38;5;241m=\u001b[39m data_objs \u001b[38;5;241m+\u001b[39m [dp], remapping_dicts\u001b[38;5;241m=\u001b[39mremapping)\n\u001b[1;32m      3\u001b[0m lca\u001b[38;5;241m.\u001b[39mlci()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_medusa_lca_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "fu, data_objs, remapping = prepare_medusa_lca_inputs(demand=demand, demand_timing_dict=demand_timing_dict, method=gwp) \n",
    "lca = bc.LCA(fu, data_objs = data_objs + [dp], remapping_dicts=remapping)\n",
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8795d",
   "metadata": {},
   "source": [
    "Let's take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MEDUSA LCA Score: 78053.71897810219\n",
      "Old static LCA Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('New MEDUSA LCA Score:', lca.score)\n",
    "print('Old static LCA Score:', slca.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616a354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.technosphere_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33803a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.biosphere_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b925ff99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mlca\u001b[49m\u001b[38;5;241m.\u001b[39mtechnosphere_matrix\u001b[38;5;241m.\u001b[39mtoarray()) \u001b[38;5;66;03m#for excel visualization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m second_items_list \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m lca\u001b[38;5;241m.\u001b[39mdicts\u001b[38;5;241m.\u001b[39mactivity\u001b[38;5;241m.\u001b[39mreversed\u001b[38;5;241m.\u001b[39mitems()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lca' is not defined"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(lca.technosphere_matrix.toarray()) #for excel visualization\n",
    "df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "second_items_list = [item[1] for item in lca.dicts.activity.reversed.items()]\n",
    "second_items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity mix background_2023 ;\n",
      "Electricity production, wind background_2023 ;\n",
      "Electricity mix background_2020 ;\n",
      "Electricity production, wind background_2020 ;\n",
      "Heat production, hydrogen foreground ;\n",
      "Hydrogen production, electrolysis foreground ;\n"
     ]
    },
    {
     "ename": "UnknownObject",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownObject\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m lca\u001b[38;5;241m.\u001b[39mactivity_dict:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mbd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], bd\u001b[38;5;241m.\u001b[39mget_activity(key)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\muell\\anaconda3\\envs\\tictac\\lib\\site-packages\\bw2data\\utils.py:440\u001b[0m, in \u001b[0;36mget_activity\u001b[1;34m(key, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m    439\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m--> 440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_node(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\muell\\anaconda3\\envs\\tictac\\lib\\site-packages\\bw2data\\utils.py:422\u001b[0m, in \u001b[0;36mget_node\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MultipleResults(\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m results for the given search\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(candidates))\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnknownObject\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidates[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnknownObject\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for key in lca.activity_dict:\n",
    "    print(bd.get_activity(key)['name'], bd.get_activity(key)[\"database\"], ';') #BW does not find the \"exploded nodes\", because they exist only in the datapackages?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5582a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
